{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I'm going to try and rewrite the burstcube class and utility function file to see if I can get things going faster than I orginally did, after all I'm a better programmer now than I was a few months ago. Additionally, there are a few different plots/images I'm hoping to take from this simulation in order to plug on my poster. \n",
    "\n",
    "\n",
    "Here's what they are:\n",
    "\n",
    "\n",
    "A skymap \n",
    "\n",
    "A summary of different geometries, and how their loc's differ\n",
    "\n",
    "\n",
    "Localization avg offset, uncertainty, which is +1 of chi squared for std. deviation. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Make sure to update these functions following what they do in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#an update to the Sky class. \n",
    "from healpy import nside2npix, pix2ang\n",
    "\n",
    "\n",
    "class Sky():\n",
    "    \"\"\"\n",
    "    Generates an array of GRB's given\n",
    "    certains strength at different sky positions.\n",
    "    \n",
    "    Output should be an array.\n",
    "    \n",
    "    The number of pixels used to obtain a higher resolution is correlated to the NSIDE specified. \n",
    "    \n",
    "    \n",
    "    # of pixels = 12 * nside ^2, also nside has to be a power of 2, but that's besides the point. \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, NSIDE, strength):\n",
    "\n",
    "        # depending on NSIDE, there will be anywhere\n",
    "        # from 12 to infinite spots on the sky w/ GRBs\n",
    "        self.Ao = strength\n",
    "        self.pixels = nside2npix(NSIDE)\n",
    "\n",
    "        # want to convert these pixels into theta phi coords.\n",
    "        self.sourceangs = []\n",
    "        for i in range(self.pixels):\n",
    "            self.sourceangs.append(pix2ang(NSIDE, i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I'm looking at the burstcube class, I'll be trying to enhance its structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"The following cell contains the \"BurstCube\" class.  This is the\n",
    "simulation I hope to use emulate the results of state of the art\n",
    "simulations on GRB localization, and use these results to characterize\n",
    "the burstcube spacecraft.\n",
    "\n",
    "For questions/comments please contact me, Noah Kasmanoff, at\n",
    "nkasmanoff@gmail.com or https://github.com/nkasmanoff\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from numpy import rad2deg, deg2rad, pi, sqrt, add, array, average\n",
    "from healpy import ang2vec, newvisufunc\n",
    "import numpy as np\n",
    "\n",
    "# sometimes one import method works, sometimes another one\n",
    "# does. Here's a quick fix.\n",
    "try:\n",
    "    from BurstCube.NoahSim import burstutils as bf\n",
    "except ImportError:\n",
    "    import burstutils as bf\n",
    "\n",
    "from random import gauss\n",
    "#import statistics as s\n",
    "\n",
    "\n",
    "# making classes of objects, allows for different instances of\n",
    "# burstcube, easy to compare.\n",
    "\n",
    "\n",
    "class BurstCube():\n",
    "    #enter initial parameter, such as the tilt and background of the instance. \n",
    "    #note that if you want the tilt to be alternating,\n",
    "    #you need to first make this true, and then enter that value when prompted. \n",
    "    def __init__(self, background, dettilt, alternating=False):\n",
    "        if alternating is False:\n",
    "            self.tilt = deg2rad(dettilt)\n",
    "            self.tiltA = self.tiltB = self.tiltC = self.tiltD = self.tilt\n",
    "        \n",
    "        else:\n",
    "            self.tiltB = (float(input(\"Please enter the second tilt (deg) \")))\n",
    "            self.tiltB = deg2rad(self.tiltB)\n",
    "            self.tiltC = self.tiltA = deg2rad(dettilt)\n",
    "            self.tiltD = self.tiltB\n",
    "        \n",
    "        self.zenith = [0, 0]\n",
    "        self.bg = background\n",
    "        self.nside = 32\n",
    "    \n",
    "    #these properties are each of the detectors initialized in the proper frame. (Spherical)\n",
    "    \n",
    "    @property\n",
    "    def detA(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and\n",
    "        localize events.  In this software package, they are labelled\n",
    "        A through D.\n",
    "\n",
    "        \"\"\"\n",
    "        return [self.zenith[0] + self.tiltA, self.zenith[1]]\n",
    "    \n",
    "    @property \n",
    "    def detB(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltB , self.zenith[1] + pi/2 ]\n",
    "    @property\n",
    "    def detC(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltC , self.zenith[1] + pi ]\n",
    "    @property \n",
    "    def detD(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltD , self.zenith[1] + 3*pi/2 ]\n",
    "    \n",
    "    @property\n",
    "    def normA(self):\n",
    "        return  ang2vec(self.detA[0],self.detA[1])\n",
    "    @property \n",
    "    def normB(self):\n",
    "        return  ang2vec(self.detB[0],self.detB[1])\n",
    "    @property\n",
    "    def normC(self):\n",
    "        return  ang2vec(self.detC[0],self.detC[1])\n",
    "    @property \n",
    "    def normD(self):\n",
    "        return  ang2vec(self.detD[0],self.detD[1])\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def dets(self):\n",
    "        return [self.normA,self.normB,self.normC,self.normD] \n",
    "\n",
    "    #now that the properties of burstucbe have been designed, now its time to test the model's localization capabilities    \n",
    "    @property\n",
    "    def initialize(self):  \n",
    "    \n",
    "    #first need to include the GRB.\n",
    "       \n",
    "        \"\"\"\n",
    "        Using x, respond2GRB will determine the sky position of an array of GRB sources assuming some inherent background noise within \n",
    "        detectors, along with fluctuations of either Gaussian or Poissonian nature. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        GRB : object\n",
    "            An instance of the separately defined \"GRBs\" class that contains a number of evenly spaced sky positions of a given strength. \n",
    "        \n",
    "        test : boolean \n",
    "            For sanity purposes, if the simulation seems to give unrealistic results, switching to test mode allows for much quicker sampling, allowing it easier to spot potential errors. \n",
    "        \n",
    "        \n",
    "        talk : boolean\n",
    "            If desired, prints position by position results. \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        localizationerrors : array\n",
    "            numpy array that contains the average localization uncertainty at each sky position. \n",
    "        \n",
    "        Additionally, response2GRB will print the sky position it is currently sampling, along with the average offset of localizations at that spot. \n",
    "        \n",
    "        \n",
    "        ---\n",
    "        Create my own GRB loading system here. \n",
    "        \"\"\"\n",
    "        \n",
    "        GRB = Sky(self.nside,1)  #inherits GRB\n",
    "            #range of values used in the fitting. \n",
    "        skypoints = len(GRB.sourceangs)   #number of GRBs you're testing\n",
    "        \n",
    "        ideal_responses = []\n",
    "        for i in range(skypoints):  #for each sample \n",
    "            \n",
    "            sourceAng = GRB.sourceangs[i]\n",
    "#                print(\"Testing a burst @ \" + str(rad2deg(sourceAng)))\n",
    "\n",
    "            \n",
    "            sourcexyz = ang2vec(sourceAng[0],sourceAng[1]) #cartesian position of the burst at this position\n",
    "            loop = 0 #I'm going to want to sample each sky position more than once,\n",
    "                    #here's where I define how many times that is\n",
    "            locunc = []\n",
    "            \n",
    "            \"\"\"A\"\"\"\n",
    "            sepA=bf.angle(sourcexyz,self.normA)  \n",
    "            xA = bf.look_up_A(self.normA,sourcexyz)\n",
    "    \n",
    "            dtheoryA=GRB.Ao*bf.response(sepA,xA)  \n",
    "                    \n",
    "            \"\"\"B\"\"\"\n",
    "            sepB=bf.angle(sourcexyz,self.normB)\n",
    "            xB = bf.look_up_B(self.normB,sourcexyz)\n",
    "            dtheoryB=GRB.Ao*bf.response(sepB,xB)  \n",
    "\n",
    "            \n",
    "            \"\"\"C\"\"\"\n",
    "            sepC=bf.angle(sourcexyz,self.normC)\n",
    "            xC =  bf.look_up_C(self.normC,sourcexyz)\n",
    "            dtheoryC=GRB.Ao*bf.response(sepC,xC)  #still need to define strength, brb and gonna do that \n",
    "\n",
    "            \"\"\"D\"\"\"\n",
    "            sepD=bf.angle(sourcexyz,self.normD)\n",
    "            xD = bf.look_up_D(self.normD,sourcexyz)\n",
    "            dtheoryD=GRB.Ao*bf.response(sepD,xD)  #still need to define strength, brb and gonna do that \n",
    "            ideal_responses.append([dtheoryA,dtheoryB,dtheoryC,dtheoryD])\n",
    "        ideal_responses = normalize(ideal_responses,axis=1)\n",
    "        for i in range(len(ideal_responses)):\n",
    "            #this is a quick fix for removing the normalizing below horizon. \n",
    "            if ideal_responses[i][0] == ideal_responses[i][1] == ideal_responses[i][2] == ideal_responses[i][3]:\n",
    "                ideal_responses[i][0] = 100\n",
    "                ideal_responses[i][1] = 100\n",
    "                ideal_responses[i][2] = 100\n",
    "                ideal_responses[i][3] = 100\n",
    "        self.ideal_data = pd.DataFrame([])\n",
    "        self.ideal_data['A'] = ideal_responses[:,0]\n",
    "        self.ideal_data['B'] = ideal_responses[:,1]\n",
    "        self.ideal_data['C'] = ideal_responses[:,2]\n",
    "        self.ideal_data['D'] = ideal_responses[:,3]\n",
    "        return self.ideal_data\n",
    "\n",
    "    \"\"\"Brief interlude..\n",
    "   \n",
    "   \n",
    "   \"\"\"\n",
    "    \n",
    "    def response2GRB(self, GRB,test=False,talk=False):  \n",
    "\n",
    "    #first need to include the GRB.\n",
    "       \n",
    "        \"\"\"\n",
    "        Using x, respond2GRB will determine the sky position of an array of GRB sources assuming some inherent background noise within \n",
    "        detectors, along with fluctuations of either Gaussian or Poissonian nature. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        GRB : object\n",
    "            An instance of the separately defined \"GRBs\" class that contains a number of evenly spaced sky positions of a given strength. \n",
    "        \n",
    "        test : boolean \n",
    "            For sanity purposes, if the simulation seems to give unrealistic results, switching to test mode allows for much quicker sampling, allowing it easier to spot potential errors. \n",
    "        \n",
    "        \n",
    "        talk : boolean\n",
    "            If desired, prints position by position results. \n",
    "        \n",
    "        Returns\n",
    "        ----------\n",
    "        localizationerrors : array\n",
    "            numpy array that contains the average localization uncertainty at each sky position. \n",
    "        \n",
    "        Additionally, response2GRB will print the sky position it is currently sampling, along with the average offset of localizations at that spot. \n",
    "        \n",
    "        \"\"\"\n",
    "        skyvals = []\n",
    "        if test:\n",
    "            nsamples = 1\n",
    "            skypoints = 1\n",
    "\n",
    "        else:\n",
    "            #range of values used in the fitting. \n",
    "            skypoints = len(GRB.sourceangs)   #number of GRBs you're testing\n",
    "            nsamples = 100\n",
    "\n",
    "        actual_responses = []\n",
    "        for i in range(skypoints):  #for each grb\n",
    "            \n",
    "            sourceAng = GRB.sourceangs[i]\n",
    "            if talk:\n",
    "                print(\"Testing bursts @ \" + str(rad2deg(sourceAng))+\", sampling it \" + str(nsamples)+ \" times\")\n",
    "\n",
    "            \n",
    "            sourcexyz = ang2vec(sourceAng[0],sourceAng[1]) #cartesian position of the burst at this position\n",
    "            loop = 0 #I'm going to want to sample each sky position more than once,\n",
    "                    #here's where I define how many times that is\n",
    "            locunc = []\n",
    "            \n",
    "            for i in range(nsamples): \n",
    "                \"\"\"A\"\"\"\n",
    "                sepA=bf.angle(sourcexyz,self.normA)  \n",
    "                xA = bf.look_up_A(self.normA,sourcexyz)\n",
    "    \n",
    "                dtheoryA=GRB.Ao*bf.response(sepA,xA)  \n",
    "                    \n",
    "                countsA = dtheoryA + self.bg\n",
    "                unccountsA = sqrt(countsA)\n",
    "                detactualA = gauss(countsA,unccountsA)\n",
    "                if detactualA-self.bg < 0:\n",
    "                    detactualA = 0\n",
    "                detcountsA = detactualA - self.bg\n",
    "                \n",
    "                \"\"\"B\"\"\"\n",
    "                sepB=bf.angle(sourcexyz,self.normB)\n",
    "                xB = bf.look_up_B(self.normB,sourcexyz)\n",
    "                dtheoryB=GRB.Ao*bf.response(sepB,xB)  \n",
    "                countsB = dtheoryB + self.bg \n",
    "                unccountsB = sqrt(countsB)\n",
    "                detactualB = gauss(countsB,unccountsB)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualB-self.bg < 0:\n",
    "                    detactualB = 0\n",
    "                    \n",
    "                detcountsB = detactualB - self.bg\n",
    "                \n",
    "            \n",
    "                \"\"\"C\"\"\"\n",
    "                sepC=bf.angle(sourcexyz,self.normC)\n",
    "                xC =  bf.look_up_C(self.normC,sourcexyz)\n",
    "                dtheoryC=GRB.Ao*bf.response(sepC,xC)  #still need to define strength, brb and gonna do that \n",
    "                countsC = dtheoryC + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsC = sqrt(countsC)\n",
    "                detactualC = gauss(countsC,unccountsC)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualC-self.bg < 0:\n",
    "                    detactualC = 0\n",
    "                    \n",
    "                detcountsC = detactualC - self.bg\n",
    "                \n",
    "                \n",
    "\n",
    "                \"\"\"D\"\"\"\n",
    "                sepD=bf.angle(sourcexyz,self.normD)\n",
    "                xD = bf.look_up_D(self.normD,sourcexyz)\n",
    "                dtheoryD=GRB.Ao*bf.response(sepD,xD)  #still need to define strength, brb and gonna do that \n",
    "                     \n",
    "                   # print(\"dtheory test: \" + str(dtheory))\n",
    "                    # this check passes too. \n",
    "                    \n",
    "                countsD = dtheoryD + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsD = sqrt(countsD)\n",
    "                detactualD = gauss(countsD,unccountsD)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualD-self.bg < 0:\n",
    "                    detactualD = 0 \n",
    "                detcountsD = detactualD - self.bg\n",
    "                arr = np.array([float(detcountsA),float(detcountsB),float(detcountsC),float(detcountsD)])\n",
    "                arr = arr.reshape(1,-1)\n",
    "              #  if talk:\n",
    "                #    print(arr)\n",
    "                normalized_arr = normalize(arr,axis=1) #converted \n",
    "            #This tab corresponds to a new sky pos being tested, will have to evaluate all of these at once maybe? \n",
    "                observed_data = pd.DataFrame([])\n",
    "                observed_data['A'] = normalized_arr[0][0]* np.ones(len(self.ideal_data))\n",
    "                observed_data['B'] = normalized_arr[0][1]* np.ones(len(self.ideal_data))\n",
    "                observed_data['C'] = normalized_arr[0][2]* np.ones(len(self.ideal_data))\n",
    "                observed_data['D'] = normalized_arr[0][3]* np.ones(len(self.ideal_data))\n",
    "        \n",
    "                #SO NOW WITH THIS OBSERVED DATA, COMPARE TO IDEAL RESPONES. \n",
    "                chiterms  = (self.ideal_data - observed_data)**2 / self.ideal_data\n",
    "                observed_data['chisquared'] = chiterms.sum(axis=1)\n",
    "                chimin = observed_data['chisquared'].loc[observed_data['chisquared'] == min(observed_data['chisquared'])].index[0]\n",
    "                recpos = pix2ang(ipix=int(chimin),nside=self.nside)\n",
    "             #   print(recpos)\n",
    "                recvec = ang2vec(recpos[0],recpos[1])\n",
    "                locoffset = np.rad2deg(bf.angle(sourcexyz,recvec))\n",
    "               # print(\"Loc offset = \" + str(locoffset) + \" deg\")\n",
    "                \n",
    "                locunc.append(locoffset)\n",
    "                #convert recpos into degrees sepearaiton.\n",
    "            locunc = np.array(locunc)\n",
    "           # nanmask = nanmask = np.isnan(locunc)\n",
    "           # locunc = locunc[~nanmask]\n",
    "            if talk:\n",
    "                print(\"Avg unc: \" + str(np.mean(locunc)))\n",
    "            skyvals.append(np.mean(locunc))\n",
    "        skyvals = np.array(skyvals)\n",
    "        return skyvals\n",
    "    \n",
    "\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this one version, see how it goes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSIDE = 4\n",
    "STRENGTH = 5000\n",
    "BACKGROUND = 10\n",
    "TILT = 45\n",
    "\n",
    "sim1 = Sky(NSIDE,STRENGTH)\n",
    "\n",
    "#run this file, and you immediately get\n",
    "testcube = BurstCube(BACKGROUND,TILT,alternating =False)\n",
    "_ = testcube.initialize #supress output for now, but it is now a property so we chilling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "locoffsets = testcube.response2GRB(sim1,talk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = np.array(locoffsets)\n",
    "newvisufunc.mollview(im,min=0, max=30,unit='Localization Accurary (degrees)',graticule=True,graticule_labels=True)\n",
    "plt.title('All Sky Localization Accuracy for BurstCube set as ' + str(TILT) + ' deg')  #should add something about design too! \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(locoffsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import nan\n",
    "x = [1400, 1500, 1600, nan, nan, nan ,1700] #Not in this exact configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nanmask = np.isnan(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x[~nanmask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huh = testcube.ideal_data.values[1616]\n",
    "shouldbe = testcube.ideal_data.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((huh - ex) **2 / huh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((shouldbe - ex) **2 / huh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shouldbe[0]**2 + shouldbe[1]**2 + shouldbe[2]**2 + shouldbe[3]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex[0]**2 + ex[1]**2 + ex[2]**2 + ex[3]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "huh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr = testcube.response2GRB(sim1,test=True,talk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_arr = testcube.ideal_response2GRB(sim1,talk = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I have a test array, and the ideal. The next step is to perform a chi square, and see which vals it aligns with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_arr  #create a d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def chi_squareds(obs,tru):\n",
    "    \"\"\"Calculate the chi squared value of the observed array and the true, the min chi aligns with the best fit. \n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    #Now for every value in this true array, index corresponds to nside value, which is then the pixel and position. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_squareds(test_arr,ideal_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ideal_arr)  #also the number of pixels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "observed_data = pd.DataFrame([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_data['A'] = test_arr[0][0]* np.ones(len(ideal_arr))\n",
    "observed_data['B'] = test_arr[0][1]* np.ones(len(ideal_arr))\n",
    "observed_data['C'] = test_arr[0][2]* np.ones(len(ideal_arr))\n",
    "observed_data['D'] = test_arr[0][3]* np.ones(len(ideal_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ideal_data = pd.DataFrame([])\n",
    "ideal_data['A'] = ideal_arr[:,0]\n",
    "ideal_data['B'] = ideal_arr[:,1]\n",
    "ideal_data['C'] = ideal_arr[:,2]\n",
    "ideal_data['D'] = ideal_arr[:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ideal_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(ideal - true) **2 / true \n",
    "\n",
    "so for each row, subtract each colum and square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiterms  = (ideal_data - observed_data)**2 / observed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiterms['chisquared'] = chiterms.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chiterms['chisquared'].loc[chiterms['chisquared'] == min(chiterms['chisquared'])].index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now convert pixel to coordinate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from healpy import pix2ang\n",
    "\n",
    "np.rad2deg(pix2ang(ipix=50,nside=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where am I leaving off before lunch?\n",
    "\n",
    "\n",
    "I have an ideal function that prints out the relative # of counts for each detector assuming no noise. \n",
    "\n",
    "I have another function that prints out the relative # of counts for each detector assuming noise. \n",
    "\n",
    "By using a chi squared at each time this point is sampled, this method allows me to infer the position by looking it up in these two tables, 'observed' and 'idea'. \n",
    "\n",
    "Next up is integrating this chi squared and dataframe action into a funciton, and plugging it into a loop. \n",
    "\n",
    "The ideal response thing should also be a separate function, otherwise it won't work unless run first. \n",
    "\n",
    "\n",
    "Or go like this\n",
    "\n",
    "1. Initialize object\n",
    "\n",
    "2. Get responses ... this won't work since of the many such sample points. \n",
    "    Possibly average response? But this def loses information so average at the end once its an uncertainty\n",
    "    \n",
    "    \n",
    "3. \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So everything that happens here is now what I hope will be what happens over every file, and will be plugged back into the burstcube class and the utility file as well.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "normalized_arr = np.array(normalize(test_arr,axis=0)) #converted \n",
    "\n",
    "#quick formating correction\n",
    "print(normalized_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_arr = np.array([normalized_arr[0][0],normalized_arr[1][0],normalized_arr[2][0],normalized_arr[3][0]])\n",
    "#this is lazy coding on my part. It's an extra line but saves me a lott of time going back making this the initial form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for this normalized array, perform chi squared fitting. \n",
    "\n",
    "It means doing things very differently than I already have. Be prepared for it to get dirty now. Sorry Noah :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"This is where the fitting begings\"\"\"\n",
    "                #coarse to fine optimization\n",
    "                chiA = bf.quad_solver(detcountsA,self.normA,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg,A=True)\n",
    "                chiB = bf.quad_solver(detcountsB,self.normB,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg,B=True)\n",
    "                chiC = bf.quad_solver(detcountsC,self.normC,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg,C=True)\n",
    "                chiD = bf.quad_solver(detcountsD,self.normD,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg,D=True)\n",
    "                \n",
    "                chisquared = add(add(chiA,chiB),add(chiC,chiD)) #adds it all up for total chi2\n",
    "                \n",
    "                #print(\"Chi squareds: \" +str(chisquared))\n",
    "                \n",
    "                \n",
    "                thetaloc, philoc, Aguess = bf.indexer(chisquared,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA)\n",
    "                recvec = ang2vec(deg2rad(thetaloc),deg2rad(philoc))\n",
    "                locoffset = rad2deg(bf.angle(sourcexyz,recvec))\n",
    "               # print(\"Loc offset = \" + str(locoffset) + \" deg\")\n",
    "                \n",
    "                locunc.append(locoffset)\n",
    "                loop +=1\n",
    "            if talk:\n",
    "                print(\"Avg loc offset = \" + str(average(locunc)) + \" deg.\")\n",
    "\n",
    "            self.localizationerrors.append(np.mean(locunc))\n",
    "        return self.localizationerrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
