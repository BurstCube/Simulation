{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GRBgenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the fastcube class, simulations for burstcube that run really fast but still pretty accurate. What sorts of customizations should I include?\n",
    "\n",
    "Sample, samples n, \n",
    "\n",
    "Keep that test feature: \n",
    "maybe have a bruteforce vs. quicker version, all about fullsky sims now though. \n",
    "\n",
    "Also need to remember how I treated past horizon spots, and what the goal should be for those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The following cell contains the \"FastCube\" class. This is the simulation I hope to use to be able to run quicker simulations. \n",
    "\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import burstutils as bf\n",
    "import random as rand\n",
    "import statistics as s\n",
    "import time as time\n",
    "\n",
    "class FastCube():\n",
    "\n",
    "    def __init__(self,background,dettilt,alternating=False):\n",
    "        if alternating == False:\n",
    "            self.tilt = np.deg2rad(dettilt)\n",
    "            self.tiltA = self.tiltB = self.tiltC = self.tiltD = self.tilt\n",
    "        \n",
    "        else:\n",
    "            self.tiltB = (float(input(\"Please enter the second tilt (deg) \")))\n",
    "            self.tiltB = np.deg2rad(self.tiltB)\n",
    "            self.tiltC = self.tiltA = np.deg2rad(dettilt)\n",
    "            self.tiltD = self.tiltB\n",
    "        \n",
    "        self.zenith = [0 , 0]\n",
    "        self.bg = background\n",
    "\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def detA(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltA , self.zenith[1] ]\n",
    "    @property \n",
    "    def detB(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltB , self.zenith[1] + np.pi/2 ]\n",
    "    @property\n",
    "    def detC(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltC , self.zenith[1] + np.pi ]\n",
    "    @property \n",
    "    def detD(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltD , self.zenith[1] + 3*np.pi/2 ]\n",
    "    @property\n",
    "    def normA(self):\n",
    "        return  hp.ang2vec(self.detA[0],self.detA[1])\n",
    "    @property \n",
    "    def normB(self):\n",
    "        return  hp.ang2vec(self.detB[0],self.detB[1])\n",
    "    @property\n",
    "    def normC(self):\n",
    "        return  hp.ang2vec(self.detC[0],self.detC[1])\n",
    "    @property \n",
    "    def normD(self):\n",
    "        return  hp.ang2vec(self.detD[0],self.detD[1])\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def dets(self):\n",
    "        return [self.normA,self.normB,self.normC,self.normD] \n",
    "    \n",
    "    \n",
    "    \n",
    "    def response2GRB(self, GRB, test=True):   #is this how I inherit? \n",
    "        start = time.time()\n",
    "        #first need to include the GRB.\n",
    "       \n",
    "        \"\"\"\n",
    "        Using least squares regression, respond2GRB will determine the sky position of an array of GRB sources assuming some inherent background noise within \n",
    "        detectors, along with fluctuations of either Gaussian or Poissonian nature. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        GRB : object\n",
    "            An instance of the separately defined \"GRBs\" class that contains a number of evenly spaced sky positions of a given strength. \n",
    "        \n",
    "        test : boolean \n",
    "            For sanity purposes, if the simulation seems to give unrealistic results, switching to test mode allows for much quicker sampling, allowing it easier to spot potential errors. \n",
    "        \n",
    "        \n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        localizationerrors : array\n",
    "            numpy array that contains the average localization uncertainty at each sky position. \n",
    "        \n",
    "        Additionally, response2GRB will print the sky position it is currently sampling, along with the average offset of localizations at that spot. \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if test:\n",
    "            sample = 1\n",
    "            samples = 50  #times  per sky pos\n",
    "            bottheta = 0\n",
    "            toptheta = 90\n",
    "            botphi = 0 \n",
    "            topphi = 360\n",
    "            botA = 0\n",
    "            topA = 1000\n",
    "            ntheta = 10   #over sky chi points\n",
    "            nphi = 37\n",
    "            nA = 100\n",
    "\n",
    "        else:\n",
    "            sample = len(GRB.sourceangs) \n",
    "            samples = 10 #times  per sky pos\n",
    "            bottheta = 0\n",
    "            toptheta = 90\n",
    "            botphi = 0 \n",
    "            topphi = 360\n",
    "            botA = 400\n",
    "            topA = 1000\n",
    "            ntheta = 31   #over sky chi points\n",
    "            nphi = 120\n",
    "            nA = 12\n",
    "        self.localizationerrors = []    \n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "        for i in range(sample):\n",
    "            sourceAng = GRB.sourceangs[i]\n",
    "          #  print(\"Testing \" + str(np.rad2deg(sourceAng)))\n",
    "           #this check passes.       \n",
    "\n",
    "            \n",
    "           # print(\"Testing at \" + str(np.rad2deg(GRB.sourceangs)))\n",
    "            sourcexyz = hp.ang2vec(sourceAng[0],sourceAng[1]) #cartesian position of the burst\n",
    "            loop = 0 #I'm going to want to sample each sky position more than once,\n",
    "                    #here's where I define how many times that is\n",
    "            locunc = []\n",
    "            while loop<samples:\n",
    "                sepA=bf.angle(sourcexyz,self.normA)\n",
    "                   # print(\"separation from A is \" + str(np.rad2deg(sepA)))\n",
    "                   #this check passes.  \n",
    "               \n",
    "                if sepA < np.pi/2: # meaning if >90, would not be facing detector.\n",
    "                    dtheoryA=GRB.Ao*bf.response(bf.angle(sourcexyz,self.normA))  #still need to define strength, brb and gonna do that \n",
    "                else: #like I was saying, has to face it!\n",
    "                    dtheoryA = 0 \n",
    "                     \n",
    "                   # print(\"dtheory test: \" + str(dtheory))\n",
    "                    # this check passes too. \n",
    "                    \n",
    "                countsA = dtheoryA + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsA = np.sqrt(countsA)\n",
    "                detactualA = rand.gauss(countsA,unccountsA)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualA-self.bg < 0:\n",
    "                    detactualA = self.bg\n",
    "                    \n",
    "                detcountsA = detactualA\n",
    "                \n",
    "                sepB=bf.angle(sourcexyz,self.normB)\n",
    "                   # print(\"separation from B is \" + str(np.rad2deg(sepB)))\n",
    "                   #this check passes.  \n",
    "               \n",
    "                if sepB < np.pi/2: # meaning if >90, would not be facing detector.\n",
    "                    dtheoryB=GRB.Ao*bf.response(bf.angle(sourcexyz,self.normB))  #still need to define strength, brb and gonna do that \n",
    "                else: #like I was saying, has to face it!\n",
    "                    dtheoryB = 0 \n",
    "                     \n",
    "                   # print(\"dtheory test: \" + str(dtheory))\n",
    "                    # this check passes too. \n",
    "                    \n",
    "                countsB = dtheoryB + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsB = np.sqrt(countsB)\n",
    "                detactualB = rand.gauss(countsB,unccountsB)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualB-self.bg < 0:\n",
    "                    detactualB = self.bg\n",
    "                    \n",
    "                detcountsB = detactualB\n",
    "\n",
    "                sepC=bf.angle(sourcexyz,self.normC)\n",
    "                   # print(\"separation from C is \" + str(np.rad2deg(sepC)))\n",
    "                   #this check passes.  \n",
    "               \n",
    "                if sepC < np.pi/2: # meaning if >90, would not be facing detector.\n",
    "                    dtheoryC=GRB.Ao*bf.response(bf.angle(sourcexyz,self.normC))  #still need to define strength, brb and gonna do that \n",
    "                else: #like I was saying, has to face it!\n",
    "                    dtheoryC = 0 \n",
    "                     \n",
    "                   # print(\"dtheory test: \" + str(dtheory))\n",
    "                    # this check passes too. \n",
    "                    \n",
    "                countsC = dtheoryC + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsC = np.sqrt(countsC)\n",
    "                detactualC = rand.gauss(countsC,unccountsC)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualC-self.bg < 0:\n",
    "                    detactualC = self.bg\n",
    "                    \n",
    "                detcountsC = detactualC\n",
    "                \n",
    "                sepD=bf.angle(sourcexyz,self.normD)\n",
    "                   # print(\"separation from D is \" + str(np.rad2deg(sepD)))\n",
    "                   #this check passes.  \n",
    "               \n",
    "                if sepD < np.pi/2: # meaning if >90, would not be facing detector.\n",
    "                    dtheoryD=GRB.Ao*bf.response(bf.angle(sourcexyz,self.normD))  #still need to define strength, brb and gonna do that \n",
    "                else: #like I was saying, has to face it!\n",
    "                    dtheoryD = 0 \n",
    "                     \n",
    "                   # print(\"dtheory test: \" + str(dtheory))\n",
    "                    # this check passes too. \n",
    "                    \n",
    "                countsD = dtheoryD + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsD = np.sqrt(countsD)\n",
    "                detactualD = rand.gauss(countsD,unccountsD)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualD-self.bg < 0:\n",
    "                    detactualD = self.bg\n",
    "                    \n",
    "                detcountsD = detactualD\n",
    "                \n",
    "                self.X_all.append([detcountsA,detcountsB,detcountsC,detcountsD])\n",
    "                #coarse to fine optimization\n",
    "                chiA = bf.quad_solver(detcountsA,self.normA,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg)\n",
    "                chiB = bf.quad_solver(detcountsB,self.normB,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg)\n",
    "                chiC = bf.quad_solver(detcountsC,self.normC,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg)\n",
    "                chiD = bf.quad_solver(detcountsD,self.normD,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg)\n",
    "                \n",
    "                chisquared = np.add(np.add(chiA,chiB),np.add(chiC,chiD)) #adds it all up for total chi2\n",
    "                \n",
    "                #print(\"Chi squareds: \" +str(chisquared))\n",
    "                \n",
    "                \n",
    "                thetaloc, philoc, Aguess = bf.indexer(chisquared,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA)\n",
    "                recvec = hp.ang2vec(np.deg2rad(thetaloc),np.deg2rad(philoc))\n",
    "                locoffset = np.rad2deg(bf.angle(sourcexyz,recvec))\n",
    "               # print(\"Loc offset = \" + str(locoffset) + \" deg\")\n",
    "                self.y_all.append([thetaloc,philoc,Aguess])\n",
    "                locunc.append(locoffset)\n",
    "                loop +=1\n",
    "            #print(\"Avg loc offset = \" + str(s.mean(locunc)) + \" deg.\")\n",
    "            self.localizationerrors.append(s.mean(locunc))\n",
    "        return self.localizationerrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRBtest = GRBgenerator.Sky(4,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fastguy = FastCube(1000,45,alternating=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115.38609671592712\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fastguy.response2GRB(GRBtest,test=False)\n",
    "end= time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fastguy.X_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now the NN Part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xall = np.array(fastguy.X_all)\n",
    "\n",
    "yall = np.array(fastguy.y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 4)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "\n",
    "# row vector via reshape\n",
    "np.shape(xall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.reshape((1, 3))\n",
    "np.shape(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain = np.split(xall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(12, input_dim=4, activation='linear'))\n",
    "model.add(Dense(102, activation='linear'))\n",
    "model.add(Dense(3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mae'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error (MAE): MAE measures the average magnitude of the errors in a set of predictions, without considering their direction. It’s the average over the test sample of the absolute differences between prediction and actual observation where all individual differences have equal weight.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93055.9242 - mean_absolute_error: 217.0678\n",
      "Epoch 2/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93078.3040 - mean_absolute_error: 217.1633\n",
      "Epoch 3/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93090.3770 - mean_absolute_error: 217.2079\n",
      "Epoch 4/50\n",
      "1920/1920 [==============================] - 0s 12us/step - loss: 93088.5724 - mean_absolute_error: 217.2005\n",
      "Epoch 5/50\n",
      "1920/1920 [==============================] - 0s 13us/step - loss: 93076.6642 - mean_absolute_error: 217.1551\n",
      "Epoch 6/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93056.0480 - mean_absolute_error: 217.0753\n",
      "Epoch 7/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93041.2082 - mean_absolute_error: 217.0112\n",
      "Epoch 8/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93030.2236 - mean_absolute_error: 216.9500\n",
      "Epoch 9/50\n",
      "1920/1920 [==============================] - 0s 12us/step - loss: 93026.6696 - mean_absolute_error: 216.9124\n",
      "Epoch 10/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93027.7749 - mean_absolute_error: 216.9018\n",
      "Epoch 11/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93030.2972 - mean_absolute_error: 216.9016\n",
      "Epoch 12/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93034.2153 - mean_absolute_error: 216.9074\n",
      "Epoch 13/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93034.4149 - mean_absolute_error: 216.9071\n",
      "Epoch 14/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93032.5397 - mean_absolute_error: 216.9057\n",
      "Epoch 15/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93028.3201 - mean_absolute_error: 216.8950\n",
      "Epoch 16/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93026.3221 - mean_absolute_error: 216.8975\n",
      "Epoch 17/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93024.7031 - mean_absolute_error: 216.9023\n",
      "Epoch 18/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93025.4645 - mean_absolute_error: 216.9127\n",
      "Epoch 19/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93025.9497 - mean_absolute_error: 216.9221\n",
      "Epoch 20/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93026.8918 - mean_absolute_error: 216.9287\n",
      "Epoch 21/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93026.9818 - mean_absolute_error: 216.9299\n",
      "Epoch 22/50\n",
      "1920/1920 [==============================] - 0s 12us/step - loss: 93026.4346 - mean_absolute_error: 216.9263\n",
      "Epoch 23/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93025.4334 - mean_absolute_error: 216.9192\n",
      "Epoch 24/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93025.2217 - mean_absolute_error: 216.9143\n",
      "Epoch 25/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93025.2173 - mean_absolute_error: 216.9090\n",
      "Epoch 26/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93024.6825 - mean_absolute_error: 216.9039\n",
      "Epoch 27/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93025.0428 - mean_absolute_error: 216.9039\n",
      "Epoch 28/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93025.0618 - mean_absolute_error: 216.9023\n",
      "Epoch 29/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93025.0575 - mean_absolute_error: 216.9019\n",
      "Epoch 30/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93024.9863 - mean_absolute_error: 216.9024\n",
      "Epoch 31/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93024.7712 - mean_absolute_error: 216.9033\n",
      "Epoch 32/50\n",
      "1920/1920 [==============================] - 0s 13us/step - loss: 93024.6636 - mean_absolute_error: 216.9043\n",
      "Epoch 33/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93024.6842 - mean_absolute_error: 216.9051\n",
      "Epoch 34/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93024.6735 - mean_absolute_error: 216.9058\n",
      "Epoch 35/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93024.8270 - mean_absolute_error: 216.9085\n",
      "Epoch 36/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93024.8420 - mean_absolute_error: 216.9092\n",
      "Epoch 37/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93024.8333 - mean_absolute_error: 216.9093\n",
      "Epoch 38/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93024.8704 - mean_absolute_error: 216.9092\n",
      "Epoch 39/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93024.7777 - mean_absolute_error: 216.9068\n",
      "Epoch 40/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93024.7091 - mean_absolute_error: 216.9058\n",
      "Epoch 41/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93024.8493 - mean_absolute_error: 216.9058\n",
      "Epoch 42/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93024.7376 - mean_absolute_error: 216.9047\n",
      "Epoch 43/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93024.7230 - mean_absolute_error: 216.9048\n",
      "Epoch 44/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93024.7489 - mean_absolute_error: 216.9048\n",
      "Epoch 45/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93025.0021 - mean_absolute_error: 216.9051\n",
      "Epoch 46/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93024.7178 - mean_absolute_error: 216.9045\n",
      "Epoch 47/50\n",
      "1920/1920 [==============================] - 0s 8us/step - loss: 93024.6934 - mean_absolute_error: 216.9050\n",
      "Epoch 48/50\n",
      "1920/1920 [==============================] - 0s 10us/step - loss: 93025.0119 - mean_absolute_error: 216.9069\n",
      "Epoch 49/50\n",
      "1920/1920 [==============================] - 0s 11us/step - loss: 93024.8263 - mean_absolute_error: 216.9076\n",
      "Epoch 50/50\n",
      "1920/1920 [==============================] - 0s 9us/step - loss: 93024.7723 - mean_absolute_error: 216.9072\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x119e9eef0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1920"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0.        ,  172.46865845,    0.        ]], dtype=float32)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.array([[1440.91398024,  1375.13145513,  1330.10174408,  1290.14606751]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1440.18999851,  1375.68773163,  1329.91204954,  1291.81638206])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1440.18999851,  1375.68773163,  1329.91204954,  1291.81638206],\n",
       "       [ 1401.01234871,  1407.4268673 ,  1349.20306728,  1303.81836212],\n",
       "       [ 1415.39987524,  1449.78360876,  1369.12781504,  1313.04372026],\n",
       "       ..., \n",
       "       [ 1016.53272338,  1003.58160115,  1000.        ,  1000.        ],\n",
       "       [ 1038.4020694 ,  1008.50332082,  1000.        ,  1000.        ],\n",
       "       [ 1019.51157439,  1040.71584411,  1000.        ,  1003.1049342 ]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  12.        ,   39.32773109,  454.54545455],\n",
       "       [  12.        ,   63.52941176,  509.09090909],\n",
       "       [  12.        ,   72.60504202,  509.09090909],\n",
       "       ..., \n",
       "       [  66.        ,  245.04201681,  400.        ],\n",
       "       [  78.        ,  260.16806723,  563.63636364],\n",
       "       [  90.        ,  178.48739496,  836.36363636]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
