{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/BurstCube/Simulation/Localization_and_Detection/NoahSim\n"
     ]
    }
   ],
   "source": [
    "cd NoahSim/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import GRBgenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the fastcube class, simulations for burstcube that run really fast but still pretty accurate. What sorts of customizations should I include?\n",
    "\n",
    "Sample, samples n, \n",
    "\n",
    "Keep that test feature: \n",
    "maybe have a bruteforce vs. quicker version, all about fullsky sims now though. \n",
    "\n",
    "Also need to remember how I treated past horizon spots, and what the goal should be for those. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The following cell contains the \"FastCube\" class. This is the simulation I hope to use to be able to run quicker simulations. \n",
    "\n",
    "import numpy as np\n",
    "import healpy as hp\n",
    "import burstutils as bf\n",
    "import random as rand\n",
    "import statistics as s\n",
    "import time as time\n",
    "\n",
    "class FastCube():\n",
    "\n",
    "    def __init__(self,background,dettilt,alternating=False):\n",
    "        if alternating == False:\n",
    "            self.tilt = np.deg2rad(dettilt)\n",
    "            self.tiltA = self.tiltB = self.tiltC = self.tiltD = self.tilt\n",
    "        \n",
    "        else:\n",
    "            self.tiltB = (float(input(\"Please enter the second tilt (deg) \")))\n",
    "            self.tiltB = np.deg2rad(self.tiltB)\n",
    "            self.tiltC = self.tiltA = np.deg2rad(dettilt)\n",
    "            self.tiltD = self.tiltB\n",
    "        \n",
    "        self.zenith = [0 , 0]\n",
    "        self.bg = background\n",
    "\n",
    "\n",
    "        \n",
    "    @property\n",
    "    def detA(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltA , self.zenith[1] ]\n",
    "    @property \n",
    "    def detB(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltB , self.zenith[1] + np.pi/2 ]\n",
    "    @property\n",
    "    def detC(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltC , self.zenith[1] + np.pi ]\n",
    "    @property \n",
    "    def detD(self):\n",
    "        \"\"\"BurstCube is composed of 4 separate scintillators to detect and localize events. \n",
    "        In this software package, they are labelled A through D. \n",
    "        \"\"\"\n",
    "        return [ self.zenith[0] + self.tiltD , self.zenith[1] + 3*np.pi/2 ]\n",
    "    @property\n",
    "    def normA(self):\n",
    "        return  hp.ang2vec(self.detA[0],self.detA[1])\n",
    "    @property \n",
    "    def normB(self):\n",
    "        return  hp.ang2vec(self.detB[0],self.detB[1])\n",
    "    @property\n",
    "    def normC(self):\n",
    "        return  hp.ang2vec(self.detC[0],self.detC[1])\n",
    "    @property \n",
    "    def normD(self):\n",
    "        return  hp.ang2vec(self.detD[0],self.detD[1])\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def dets(self):\n",
    "        return [self.normA,self.normB,self.normC,self.normD] \n",
    "    \n",
    "    \n",
    "    \n",
    "    def response2GRB(self, GRB, test=True):   #is this how I inherit? \n",
    "        start = time.time()\n",
    "        #first need to include the GRB.\n",
    "       \n",
    "        \"\"\"\n",
    "        Using least squares regression, respond2GRB will determine the sky position of an array of GRB sources assuming some inherent background noise within \n",
    "        detectors, along with fluctuations of either Gaussian or Poissonian nature. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        GRB : object\n",
    "            An instance of the separately defined \"GRBs\" class that contains a number of evenly spaced sky positions of a given strength. \n",
    "        \n",
    "        test : boolean \n",
    "            For sanity purposes, if the simulation seems to give unrealistic results, switching to test mode allows for much quicker sampling, allowing it easier to spot potential errors. \n",
    "        \n",
    "        \n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        localizationerrors : array\n",
    "            numpy array that contains the average localization uncertainty at each sky position. \n",
    "        \n",
    "        Additionally, response2GRB will print the sky position it is currently sampling, along with the average offset of localizations at that spot. \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        if test:\n",
    "            sample = 1\n",
    "            samples = 500  #times  per sky pos\n",
    "            bottheta = 0\n",
    "            toptheta = 90\n",
    "            botphi = 0 \n",
    "            topphi = 360\n",
    "            botA = 0\n",
    "            topA = 1000\n",
    "            ntheta = 10   #over sky chi points\n",
    "            nphi = 37\n",
    "            nA = 100\n",
    "\n",
    "        else:\n",
    "            sample = len(GRB.sourceangs) \n",
    "            samples = 10 #times  per sky pos\n",
    "            bottheta = 0\n",
    "            toptheta = 90\n",
    "            botphi = 0 \n",
    "            topphi = 360\n",
    "            botA = 400\n",
    "            topA = 1000\n",
    "            ntheta = 31   #over sky chi points\n",
    "            nphi = 120\n",
    "            nA = 12\n",
    "        self.localizationerrors = []    \n",
    "        self.X_all = []\n",
    "        self.y_all = []\n",
    "        for i in range(sample):\n",
    "            sourceAng = GRB.sourceangs[i]\n",
    "          # print(\"Testing \" + str(np.rad2deg(sourceAng)))\n",
    "           #this check passes.       \n",
    "\n",
    "            \n",
    "           # print(\"Testing at \" + str(np.rad2deg(GRB.sourceangs)))\n",
    "            sourcexyz = hp.ang2vec(sourceAng[0],sourceAng[1]) #cartesian position of the burst\n",
    "            loop = 0 #I'm going to want to sample each sky position more than once,\n",
    "                    #here's where I define how many times that is\n",
    "            locunc = []\n",
    "            while loop<samples:\n",
    "                sepA=bf.angle(sourcexyz,self.normA)\n",
    "                   # print(\"separation from A is \" + str(np.rad2deg(sepA)))\n",
    "                   #this check passes.  \n",
    "               \n",
    "                if sepA < np.pi/2: # meaning if >90, would not be facing detector.\n",
    "                    dtheoryA=GRB.Ao*bf.response(bf.angle(sourcexyz,self.normA))  #still need to define strength, brb and gonna do that \n",
    "                else: #like I was saying, has to face it!\n",
    "                    dtheoryA = 0 \n",
    "                     \n",
    "                   # print(\"dtheory test: \" + str(dtheory))\n",
    "                    # this check passes too. \n",
    "                    \n",
    "                countsA = dtheoryA + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsA = np.sqrt(countsA)\n",
    "                detactualA = rand.gauss(countsA,unccountsA)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualA-self.bg < 0:\n",
    "                    detactualA = self.bg\n",
    "                    \n",
    "                detcountsA = detactualA\n",
    "                \n",
    "                sepB=bf.angle(sourcexyz,self.normB)\n",
    "                   # print(\"separation from B is \" + str(np.rad2deg(sepB)))\n",
    "                   #this check passes.  \n",
    "               \n",
    "                if sepB < np.pi/2: # meaning if >90, would not be facing detector.\n",
    "                    dtheoryB=GRB.Ao*bf.response(bf.angle(sourcexyz,self.normB))  #still need to define strength, brb and gonna do that \n",
    "                else: #like I was saying, has to face it!\n",
    "                    dtheoryB = 0 \n",
    "                     \n",
    "                   # print(\"dtheory test: \" + str(dtheory))\n",
    "                    # this check passes too. \n",
    "                    \n",
    "                countsB = dtheoryB + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsB = np.sqrt(countsB)\n",
    "                detactualB = rand.gauss(countsB,unccountsB)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualB-self.bg < 0:\n",
    "                    detactualB = self.bg\n",
    "                    \n",
    "                detcountsB = detactualB\n",
    "\n",
    "                sepC=bf.angle(sourcexyz,self.normC)\n",
    "                   # print(\"separation from C is \" + str(np.rad2deg(sepC)))\n",
    "                   #this check passes.  \n",
    "               \n",
    "                if sepC < np.pi/2: # meaning if >90, would not be facing detector.\n",
    "                    dtheoryC=GRB.Ao*bf.response(bf.angle(sourcexyz,self.normC))  #still need to define strength, brb and gonna do that \n",
    "                else: #like I was saying, has to face it!\n",
    "                    dtheoryC = 0 \n",
    "                     \n",
    "                   # print(\"dtheory test: \" + str(dtheory))\n",
    "                    # this check passes too. \n",
    "                    \n",
    "                countsC = dtheoryC + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsC = np.sqrt(countsC)\n",
    "                detactualC = rand.gauss(countsC,unccountsC)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualC-self.bg < 0:\n",
    "                    detactualC = self.bg\n",
    "                    \n",
    "                detcountsC = detactualC\n",
    "                \n",
    "                sepD=bf.angle(sourcexyz,self.normD)\n",
    "                   # print(\"separation from D is \" + str(np.rad2deg(sepD)))\n",
    "                   #this check passes.  \n",
    "               \n",
    "                if sepD < np.pi/2: # meaning if >90, would not be facing detector.\n",
    "                    dtheoryD=GRB.Ao*bf.response(bf.angle(sourcexyz,self.normD))  #still need to define strength, brb and gonna do that \n",
    "                else: #like I was saying, has to face it!\n",
    "                    dtheoryD = 0 \n",
    "                     \n",
    "                   # print(\"dtheory test: \" + str(dtheory))\n",
    "                    # this check passes too. \n",
    "                    \n",
    "                countsD = dtheoryD + self.bg #another artifact, incl this background effect somewhere\n",
    "                unccountsD = np.sqrt(countsD)\n",
    "                detactualD = rand.gauss(countsD,unccountsD)  #there is a lot of noise, present, updating it now. \n",
    "                if detactualD-self.bg < 0:\n",
    "                    detactualD = self.bg\n",
    "                    \n",
    "                detcountsD = detactualD\n",
    "                \n",
    "                self.X_all.append([detcountsA,detcountsB,detcountsC,detcountsD])\n",
    "                #coarse to fine optimization\n",
    "                chiA = bf.quad_solver(detcountsA,self.normA,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg)\n",
    "                chiB = bf.quad_solver(detcountsB,self.normB,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg)\n",
    "                chiC = bf.quad_solver(detcountsC,self.normC,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg)\n",
    "                chiD = bf.quad_solver(detcountsD,self.normD,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA,self.bg)\n",
    "                \n",
    "                chisquared = np.add(np.add(chiA,chiB),np.add(chiC,chiD)) #adds it all up for total chi2\n",
    "                \n",
    "                #print(\"Chi squareds: \" +str(chisquared))\n",
    "                \n",
    "                \n",
    "                thetaloc, philoc, Aguess = bf.indexer(chisquared,bottheta,toptheta,botphi,topphi,botA,topA,ntheta,nphi,nA)\n",
    "                recvec = hp.ang2vec(np.deg2rad(thetaloc),np.deg2rad(philoc))\n",
    "                locoffset = np.rad2deg(bf.angle(sourcexyz,recvec))\n",
    "               # print(\"Loc offset = \" + str(locoffset) + \" deg\")\n",
    "                self.y_all.append([thetaloc,philoc,Aguess])\n",
    "                locunc.append(locoffset)\n",
    "                loop +=1\n",
    "            #print(\"Avg loc offset = \" + str(s.mean(locunc)) + \" deg.\")\n",
    "            self.localizationerrors.append(s.mean(locunc))\n",
    "        return self.localizationerrors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GRBtest = GRBgenerator.Sky(2,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fastguy = FastCube(1000,45,alternating=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.326045274734497\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "fastguy.response2GRB(GRBtest,test=True)\n",
    "end= time.time()\n",
    "\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fastguy.y_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now the NN Part!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/noahkasmanoff/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xall = np.array(fastguy.X_all)\n",
    "\n",
    "yall = np.array(fastguy.y_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = MLPRegressor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf.hidden_layer_sizes=5000\n",
    "clf.n_layers_=5000\n",
    "clf.verbose=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 15425.21759749\n",
      "Iteration 2, loss = 11023.03737243\n",
      "Iteration 3, loss = 1295.68627490\n",
      "Iteration 4, loss = 5070.94366816\n",
      "Iteration 5, loss = 698.11614350\n",
      "Iteration 6, loss = 2270.23425849\n",
      "Iteration 7, loss = 1028.88388171\n",
      "Iteration 8, loss = 696.77050278\n",
      "Iteration 9, loss = 1043.42306914\n",
      "Iteration 10, loss = 210.23624991\n",
      "Iteration 11, loss = 667.54504773\n",
      "Iteration 12, loss = 225.52613522\n",
      "Iteration 13, loss = 350.79236286\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=5000, learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(xall,yall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 21.65692853,  45.95874145, 473.16597437]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(np.array([[1445.15726843, 1464.58808801, 1350.0381453 , 1245.37103302]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1445.15726843, 1464.58808801, 1350.0381453 , 1245.37103302])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 21.        ,  66.55462185, 509.09090909])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yall[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23.55646431,  45.        ],\n",
       "       [ 23.55646431, 135.        ],\n",
       "       [ 23.55646431, 225.        ],\n",
       "       [ 23.55646431, 315.        ],\n",
       "       [ 48.1896851 ,  22.5       ],\n",
       "       [ 48.1896851 ,  67.5       ],\n",
       "       [ 48.1896851 , 112.5       ],\n",
       "       [ 48.1896851 , 157.5       ],\n",
       "       [ 48.1896851 , 202.5       ],\n",
       "       [ 48.1896851 , 247.5       ],\n",
       "       [ 48.1896851 , 292.5       ],\n",
       "       [ 48.1896851 , 337.5       ],\n",
       "       [ 70.52877937,   0.        ],\n",
       "       [ 70.52877937,  45.        ],\n",
       "       [ 70.52877937,  90.        ],\n",
       "       [ 70.52877937, 135.        ],\n",
       "       [ 70.52877937, 180.        ],\n",
       "       [ 70.52877937, 225.        ],\n",
       "       [ 70.52877937, 270.        ],\n",
       "       [ 70.52877937, 315.        ],\n",
       "       [ 90.        ,  22.5       ],\n",
       "       [ 90.        ,  67.5       ],\n",
       "       [ 90.        , 112.5       ],\n",
       "       [ 90.        , 157.5       ],\n",
       "       [ 90.        , 202.5       ],\n",
       "       [ 90.        , 247.5       ],\n",
       "       [ 90.        , 292.5       ],\n",
       "       [ 90.        , 337.5       ],\n",
       "       [109.47122063,   0.        ],\n",
       "       [109.47122063,  45.        ],\n",
       "       [109.47122063,  90.        ],\n",
       "       [109.47122063, 135.        ],\n",
       "       [109.47122063, 180.        ],\n",
       "       [109.47122063, 225.        ],\n",
       "       [109.47122063, 270.        ],\n",
       "       [109.47122063, 315.        ],\n",
       "       [131.8103149 ,  22.5       ],\n",
       "       [131.8103149 ,  67.5       ],\n",
       "       [131.8103149 , 112.5       ],\n",
       "       [131.8103149 , 157.5       ],\n",
       "       [131.8103149 , 202.5       ],\n",
       "       [131.8103149 , 247.5       ],\n",
       "       [131.8103149 , 292.5       ],\n",
       "       [131.8103149 , 337.5       ],\n",
       "       [156.44353569,  45.        ],\n",
       "       [156.44353569, 135.        ],\n",
       "       [156.44353569, 225.        ],\n",
       "       [156.44353569, 315.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rad2deg(GRBtest.sourceangs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 23.55646431,  45.        ],\n",
       "       [ 23.55646431, 135.        ],\n",
       "       [ 23.55646431, 225.        ],\n",
       "       [ 23.55646431, 315.        ],\n",
       "       [ 48.1896851 ,  22.5       ],\n",
       "       [ 48.1896851 ,  67.5       ],\n",
       "       [ 48.1896851 , 112.5       ],\n",
       "       [ 48.1896851 , 157.5       ],\n",
       "       [ 48.1896851 , 202.5       ],\n",
       "       [ 48.1896851 , 247.5       ],\n",
       "       [ 48.1896851 , 292.5       ],\n",
       "       [ 48.1896851 , 337.5       ],\n",
       "       [ 70.52877937,   0.        ],\n",
       "       [ 70.52877937,  45.        ],\n",
       "       [ 70.52877937,  90.        ],\n",
       "       [ 70.52877937, 135.        ],\n",
       "       [ 70.52877937, 180.        ],\n",
       "       [ 70.52877937, 225.        ],\n",
       "       [ 70.52877937, 270.        ],\n",
       "       [ 70.52877937, 315.        ],\n",
       "       [ 90.        ,  22.5       ],\n",
       "       [ 90.        ,  67.5       ],\n",
       "       [ 90.        , 112.5       ],\n",
       "       [ 90.        , 157.5       ],\n",
       "       [ 90.        , 202.5       ],\n",
       "       [ 90.        , 247.5       ],\n",
       "       [ 90.        , 292.5       ],\n",
       "       [ 90.        , 337.5       ],\n",
       "       [109.47122063,   0.        ],\n",
       "       [109.47122063,  45.        ],\n",
       "       [109.47122063,  90.        ],\n",
       "       [109.47122063, 135.        ],\n",
       "       [109.47122063, 180.        ],\n",
       "       [109.47122063, 225.        ],\n",
       "       [109.47122063, 270.        ],\n",
       "       [109.47122063, 315.        ],\n",
       "       [131.8103149 ,  22.5       ],\n",
       "       [131.8103149 ,  67.5       ],\n",
       "       [131.8103149 , 112.5       ],\n",
       "       [131.8103149 , 157.5       ],\n",
       "       [131.8103149 , 202.5       ],\n",
       "       [131.8103149 , 247.5       ],\n",
       "       [131.8103149 , 292.5       ],\n",
       "       [131.8103149 , 337.5       ],\n",
       "       [156.44353569,  45.        ],\n",
       "       [156.44353569, 135.        ],\n",
       "       [156.44353569, 225.        ],\n",
       "       [156.44353569, 315.        ]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.rad2deg(GRBtest.sourceangs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moral of the story: \n",
    "This ANN concept works if the net is huge, and you're starting if off with very small sample regions, otherwise its a waste of time. Loss is going to be big always too. Cool proof of concept above, but not seemingly appliciable in pracrtice unless I merge together a net for every single sky position for every different possible detector orientation which is absurd."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
